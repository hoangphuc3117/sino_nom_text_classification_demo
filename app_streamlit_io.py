"""
Streamlit Demo for Sino-Nom Text Classification
Using BERT-LSTM Model with 6 Classes
Optimized for Streamlit Cloud deployment
"""
import streamlit as st
import numpy as np
import torch
import torch.nn as nn
from transformers import BertModel, BertTokenizer
import json
import os
import re
# ThÃªm cÃ¡c import cho OCR API
import requests
import base64
from PIL import Image
import io
import kagglehub
# ThÃªm import cho Jiayan NLP vá»›i error handling
# Disabled due to kenlm compatibility issues with Python 3.13
try:
    # from jiayan import load_lm, CRFSentencizer, CharHMMTokenizer
    JIAYAN_AVAILABLE = False  # Force disable
except ImportError:
    JIAYAN_AVAILABLE = False
    CRFSentencizer = None
    CharHMMTokenizer = None
    load_lm = None

# Set page config
st.set_page_config(
    page_title="Sino-Nom Text Classification",
    page_icon="ğŸ“œ",
    layout="wide"
)

# Custom CSS for better styling
st.markdown("""
<style>
/* Custom styling for text areas */
.stTextArea > div > div > textarea {
    font-family: 'Courier New', monospace !important;
    font-size: 14px !important;
    color: #000000 !important;
    background-color: #f8f9fa !important;
    border: 1px solid #dee2e6 !important;
    border-radius: 8px !important;
    padding: 12px !important;
    line-height: 1.6 !important;
}

/* Compact margins for text areas */
.stTextArea {
    margin: 8px 0px !important;
}

/* Label styling */
.stMarkdown p {
    margin-bottom: 8px !important;
}

/* Result container styling */
.result-container {
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    padding: 20px;
    border-radius: 12px;
    margin: 16px 0px;
    color: white;
    text-align: center;
    box-shadow: 0 4px 15px rgba(0,0,0,0.1);
}

.result-title {
    font-size: 1.8em;
    font-weight: bold;
    margin: 0;
    text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
}

.result-subtitle {
    color: rgba(255,255,255,0.9);
    margin: 8px 0 0 0;
    font-size: 1em;
}

/* Confidence scores styling */
.confidence-container {
    background: #f8f9fa;
    padding: 16px;
    border-radius: 8px;
    margin: 8px 0px;
}

/* Alert styling for Streamlit Cloud */
.streamlit-info {
    background: #e1f5fe;
    padding: 16px;
    border-radius: 8px;
    border-left: 5px solid #0288d1;
    margin: 16px 0;
}
</style>
""", unsafe_allow_html=True)

# Constants
MODEL_DIR = "models_lstm_6class"
BERT_MODEL_NAME = "Jihuai/bert-ancient-chinese"
MAX_LEN = 128

# HÃ¡n-NÃ´m character processing functions
def is_han_nom_char(char):
    """Kiá»ƒm tra xem kÃ½ tá»± cÃ³ pháº£i lÃ  HÃ¡n-NÃ´m khÃ´ng"""
    # Kiá»ƒm tra cÃ¡c range Unicode cho chá»¯ HÃ¡n
    return any([
        '\u4e00' <= char <= '\u9fff',  # CJK Unified Ideographs
        '\u3400' <= char <= '\u4dbf',  # CJK Extension A
        '\u20000' <= char <= '\u2a6df', # CJK Extension B
        '\u2a700' <= char <= '\u2b73f', # CJK Extension C
        '\u2b740' <= char <= '\u2b81f', # CJK Extension D
        '\u2b820' <= char <= '\u2ceaf', # CJK Extension E
        '\u2ceb0' <= char <= '\u2ebef', # CJK Extension F
    ])

def filter_han_nom_text(text):
    """Lá»c chá»‰ giá»¯ láº¡i kÃ½ tá»± HÃ¡n-NÃ´m"""
    return ''.join([char for char in text if is_han_nom_char(char)])

@st.cache_resource
def load_jiayan_models():
    """Load Jiayan models - disabled due to kenlm compatibility issues"""
    st.info("ğŸ’¡ Jiayan processing disabled due to Python 3.13 compatibility. Using basic text processing.")
    return None, None

def preprocess_han_nom_text(text):
    """Tiá»n xá»­ lÃ½ vÄƒn báº£n HÃ¡n-NÃ´m: tÃ¡ch cÃ¢u vÃ  lá»c kÃ½ tá»±"""
    # Lá»c chá»‰ giá»¯ kÃ½ tá»± HÃ¡n-NÃ´m
    filtered_text = filter_han_nom_text(text)
    
    if not filtered_text.strip():
        return []
    
    # Táº£i Jiayan models náº¿u cÃ³
    sentencizer, tokenizer = load_jiayan_models()
    
    sentences = []
    if sentencizer:
        try:
            # Sá»­ dá»¥ng Jiayan Ä‘á»ƒ tÃ¡ch cÃ¢u
            sentences = sentencizer.sentencize(filtered_text)
        except Exception as e:
            st.warning(f"Lá»—i khi sá»­ dá»¥ng Jiayan sentencizer: {e}")
            sentences = []
    
    # Fallback: dÃ¹ng regex Ä‘Æ¡n giáº£n
    if not sentences:
        # TÃ¡ch theo dáº¥u cÃ¢u truyá»n thá»‘ng
        sentences = re.split(r'[,ã€‚ï¼Œï¼›ï¼š""ï¼ˆï¼‰ã€Šã€‹]', filtered_text)
        sentences = [s.strip() for s in sentences if s.strip()]
    
    return sentences

# Model Definition
class BertLSTMClassifier(nn.Module):
    def __init__(self, input_dim=768, hidden_dim=256, num_layers=3, dropout=0.5, num_classes=6):
        super().__init__()
        self.lstm = nn.LSTM(
            input_dim, hidden_dim, num_layers,
            batch_first=True, dropout=dropout, bidirectional=True
        )
        self.dropout = nn.Dropout(dropout)
        self.fc = nn.Linear(hidden_dim * 2, num_classes)
    
    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        out = self.dropout(lstm_out)
        out = self.fc(out)
        return out

@st.cache_resource
def load_models():
    """Load all models and templates with error handling for Streamlit Cloud"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # Load class info
        class_info_path = os.path.join(MODEL_DIR, "class_info.json")
        if not os.path.exists(class_info_path):
            st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y file {class_info_path}")
            return None
            
        with open(class_info_path, "r") as f:
            class_info = json.load(f)
        
        class_names = class_info["class_names"]
        num_classes = class_info["num_classes"]
        
        # Load BERT model and tokenizer
        tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_NAME)
        bert_model = BertModel.from_pretrained(BERT_MODEL_NAME, use_safetensors=True).to(device)
        bert_model.eval()
        
        # Load LSTM classifier
        lstm_model = BertLSTMClassifier(num_classes=num_classes).to(device)
        model_path = os.path.join(MODEL_DIR, "best_model.pt")
        if not os.path.exists(model_path):
            st.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y file mÃ´ hÃ¬nh {model_path}")
            return None
            
        lstm_model.load_state_dict(torch.load(model_path, map_location=device))
        lstm_model.eval()
        
        # Load templates
        templates = {}
        for i, name in enumerate(class_names):
            template_file = os.path.join(MODEL_DIR, f"template_{name.lower()}.npy")
            if os.path.exists(template_file):
                templates[i] = np.load(template_file)
            else:
                st.warning(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y template file {template_file}")
                # Táº¡o template máº·c Ä‘á»‹nh
                templates[i] = np.random.random((128, 768))
        
        return tokenizer, bert_model, lstm_model, templates, class_names, num_classes, device
        
    except Exception as e:
        st.error(f"âŒ Lá»—i khi táº£i models: {e}")
        return None

def extract_bert_features(text, tokenizer, bert_model, device, max_len=128):
    """Extract BERT features from text"""
    encoded = tokenizer(
        text, 
        padding='max_length', 
        truncation=True, 
        max_length=max_len, 
        return_tensors='pt'
    )
    
    input_ids = encoded['input_ids'].to(device)
    attention_mask = encoded['attention_mask'].to(device)
    
    with torch.no_grad():
        outputs = bert_model(input_ids, attention_mask=attention_mask)
        features = outputs.last_hidden_state.cpu().numpy()
    
    return features

def make_prob_table(logits, num_classes=6):
    """Convert logits to probability table using softmax"""
    probs = torch.softmax(torch.FloatTensor(logits), dim=-1).numpy()
    return probs

def predict_with_templates(prob_table, templates, num_classes=6):
    """Classify using nearest template (Euclidean distance)"""
    distances = np.zeros((prob_table.shape[0], num_classes))
    
    for class_id in range(num_classes):
        if class_id in templates:
            dist = np.sqrt(np.sum((prob_table - templates[class_id]) ** 2, axis=(1, 2)))
            distances[:, class_id] = dist
        else:
            distances[:, class_id] = np.inf  # Náº¿u khÃ´ng cÃ³ template
    
    return np.argmin(distances, axis=1), distances

def classify_text(text, tokenizer, bert_model, lstm_model, templates, class_names, num_classes, device):
    """Classify a single text"""
    # Extract BERT features
    features = extract_bert_features(text, tokenizer, bert_model, device)
    
    # Get LSTM logits
    with torch.no_grad():
        logits = lstm_model(torch.FloatTensor(features).to(device)).cpu().numpy()
    
    # Get probability table
    prob_table = make_prob_table(logits, num_classes)
    
    # Predict with templates
    pred_idx, distances = predict_with_templates(prob_table, templates, num_classes)
    
    # Calculate confidence (inverse of distance, normalized)
    all_dists = distances[0]
    
    # Convert distances to similarity scores (inverse)
    similarities = 1 / (1 + all_dists)
    confidence = similarities / similarities.sum()
    
    return class_names[pred_idx[0]], confidence, pred_idx[0]

# OCR API Configuration - sá»­ dá»¥ng external API hoáº·c secrets
def get_ocr_api_url():
    """Get OCR API URL from secrets or use default"""
    try:
        # Thá»­ láº¥y tá»« Streamlit secrets
        return st.secrets.get("OCR_API_URL", "https://kimhannom.clc.hcmus.edu.vn/meta-ocr-normal/nom-ocr")
    except:
        # Fallback URL
        return "https://kimhannom.clc.hcmus.edu.vn/meta-ocr-normal/nom-ocr"

def call_ocr_api(base64_image):
    """Call OCR API with error handling"""
    try:
        headers = {
            'User-Agent': 'StreamlitApp',
            'Content-Type': 'application/json'
        }
        
        if isinstance(base64_image, bytes):
            base64_str = base64.b64encode(base64_image).decode('utf-8')
        else:
            base64_str = base64_image

        payload = {
            "base64Data": base64_str, 
            "lang_type": 2, 
            "reading_direction": 1
        }
        
        ocr_url = get_ocr_api_url()
        response = requests.post(ocr_url, json=payload, headers=headers, verify=False, timeout=120)
        return response
        
    except requests.exceptions.Timeout:
        st.error("â±ï¸ OCR API timeout. Vui lÃ²ng thá»­ láº¡i.")
        return None
    except requests.exceptions.RequestException as e:
        st.error(f"ğŸŒ Lá»—i káº¿t ná»‘i OCR API: {e}")
        return None
    except Exception as e:
        st.error(f"âŒ Lá»—i khi gá»i OCR API: {e}")
        return None

def run_ocr_on_image(image_bytes):
    """Perform OCR using external API with error handling"""
    try:
        # Äáº£m báº£o image_bytes lÃ  bytes há»£p lá»‡
        if not isinstance(image_bytes, bytes) or len(image_bytes) == 0:
            return '', None
            
        # Validate image format
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    except Exception as e:
        st.error(f"âŒ Lá»—i khi xá»­ lÃ½ áº£nh: {str(e)}")
        return '', None
    
    # Gá»i OCR API
    api_result = call_ocr_api(image_bytes)
    if not api_result:
        return '', None
    
    raw_text = ""
    
    # Xá»­ lÃ½ káº¿t quáº£ tá»« API
    if api_result.status_code == 200:
        try:
            ocr_response_json = api_result.json()
            ocr_text_list = ocr_response_json.get("ocrResult", [])
            raw_text = "\\n".join(ocr_text_list) if ocr_text_list else ""
        except Exception as e:
            st.error(f"âŒ Lá»—i khi parse JSON response: {e}")
            return '', None
    else:
        st.error(f"âŒ OCR API tráº£ vá» lá»—i: {api_result.status_code}")
        return '', None
    
    if raw_text:
        # Hiá»ƒn thá»‹ vÄƒn báº£n Ä‘Ã£ nháº­n diá»‡n
        st.markdown("**VÄƒn báº£n Ä‘Ã£ nháº­n diá»‡n:**")
        st.text_area("VÄƒn báº£n gá»‘c", value=raw_text, height=120, disabled=True, label_visibility="hidden")

        # Tiá»n xá»­ lÃ½ vÄƒn báº£n HÃ¡n-NÃ´m
        if raw_text.strip():
            processed_sentences = preprocess_han_nom_text(raw_text)
            
            if processed_sentences:
                # Hiá»ƒn thá»‹ cÃ¡c cÃ¢u sau khi xá»­ lÃ½
                st.markdown("**VÄƒn báº£n sau khi xá»­ lÃ½:**")
                processed_text_display = '\\n'.join(processed_sentences)
                st.text_area("VÄƒn báº£n Ä‘Ã£ xá»­ lÃ½", value=processed_text_display, height=100, disabled=True, label_visibility="hidden")
                
                # GhÃ©p láº¡i thÃ nh vÄƒn báº£n hoÃ n chá»‰nh Ä‘á»ƒ phÃ¢n loáº¡i
                processed_text = ' '.join(processed_sentences)
                return processed_text, api_result
            else:
                st.info("ğŸ’¡ Sá»­ dá»¥ng vÄƒn báº£n gá»‘c do khÃ´ng tÃ¡ch Ä‘Æ°á»£c cÃ¢u HÃ¡n-NÃ´m.")
                return raw_text, api_result
    else:
        st.warning("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n vÄƒn báº£n trong áº£nh.")
    
    return raw_text, api_result

def main():
    st.title("ğŸ“œ Sino-Nom Text Classification")
    st.markdown("### PhÃ¢n loáº¡i vÄƒn báº£n HÃ¡n-NÃ´m sá»­ dá»¥ng mÃ´ hÃ¬nh BERT-LSTM")
    
    # Streamlit Cloud info
    st.markdown("""
    <div class="streamlit-info">
        <strong>ğŸš€ Deployed on Streamlit Cloud</strong><br>
        á»¨ng dá»¥ng nÃ y sá»­ dá»¥ng BERT-LSTM Ä‘á»ƒ phÃ¢n loáº¡i vÄƒn báº£n HÃ¡n-NÃ´m thÃ nh 6 loáº¡i: Y há»c, Lá»‹ch sá»­, VÄƒn há»c, Pháº­t giÃ¡o, CÃ´ng giÃ¡o, vÃ  KhÃ¡c.
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Load models with progress indicator
    model_data = None
    with st.spinner("ğŸ”„ Äang táº£i mÃ´ hÃ¬nh... (cÃ³ thá»ƒ máº¥t vÃ i phÃºt láº§n Ä‘áº§u)"):
        model_data = load_models()
    
    if not model_data:
        st.error("âŒ KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh. Vui lÃ²ng kiá»ƒm tra láº¡i.")
        st.stop()
        
    tokenizer, bert_model, lstm_model, templates, class_names, num_classes, device = model_data
    st.success(f"âœ… ÄÃ£ táº£i mÃ´ hÃ¬nh thÃ nh cÃ´ng! (Device: {device})")
    
    # Display class labels
    st.markdown("**CÃ¡c loáº¡i vÄƒn báº£n (Categories):**")
    cols = st.columns(6)
    category_icons = {
        "Medical": "ğŸ¥",
        "History": "ğŸ“š", 
        "Literature": "ğŸ“–",
        "Buddhism": "ğŸª·",
        "Catholics": "â›ª",
        "Others": "ğŸ“‹"
    }
    
    for i, (col, name) in enumerate(zip(cols, class_names)):
        with col:
            st.info(f"{category_icons.get(name, 'ğŸ“„')} {name}")
    
    st.markdown("---")
    
    # Upload image or text input
    st.markdown("### ğŸ“ Nháº­p vÄƒn báº£n hoáº·c upload hÃ¬nh áº£nh Ä‘á»ƒ phÃ¢n loáº¡i")
    tab1, tab2 = st.tabs(["ğŸ“¤ Upload hÃ¬nh áº£nh", "âœï¸ Nháº­p vÄƒn báº£n"])

    with tab1:
        st.markdown("**Chá»n hÃ¬nh áº£nh chá»©a vÄƒn báº£n HÃ¡n-NÃ´m Ä‘á»ƒ tá»± Ä‘á»™ng nháº­n diá»‡n vÃ  phÃ¢n loáº¡i:**")
        uploaded_file = st.file_uploader(
            "Chá»n file áº£nh",
            type=["jpg", "jpeg", "png"],
            help="Há»— trá»£ cÃ¡c Ä‘á»‹nh dáº¡ng: JPG, JPEG, PNG. KÃ­ch thÆ°á»›c tá»‘i Ä‘a: 200MB"
        )
        
        if uploaded_file is not None:
            # Äá»c bytes tá»« file uploader
            image_bytes = uploaded_file.getvalue() if hasattr(uploaded_file, 'getvalue') else uploaded_file.read()
            
            # Layout responsive
            img_col, result_col = st.columns([1, 2])
            
            with img_col:
                try:
                    image = Image.open(io.BytesIO(image_bytes))
                    st.image(image, caption="ğŸ“· áº¢nh Ä‘Ã£ upload", use_column_width=True)
                except Exception as e:
                    st.error(f"âŒ Lá»—i hiá»ƒn thá»‹ áº£nh: {str(e)}")
                    st.stop()
            
            with result_col:
                # Thá»±c hiá»‡n OCR vÃ  phÃ¢n loáº¡i
                with st.spinner("ğŸ”„ Äang nháº­n diá»‡n vÃ  phÃ¢n loáº¡i..."):
                    text_from_image, ocr_result = run_ocr_on_image(image_bytes)
                
                if text_from_image and text_from_image.strip():
                    # PhÃ¢n loáº¡i vÄƒn báº£n
                    with st.spinner("ğŸ¤– Äang phÃ¢n loáº¡i ná»™i dung..."):
                        pred_label, confidence, pred_idx = classify_text(
                            text_from_image, tokenizer, bert_model, lstm_model, 
                            templates, class_names, num_classes, device
                        )
                    
                    # Hiá»ƒn thá»‹ káº¿t quáº£
                    st.markdown("### ğŸ“Š Káº¿t quáº£ phÃ¢n loáº¡i tá»± Ä‘á»™ng")
                    
                    main_result, confidence_scores = st.columns([1, 1])
                    
                    with main_result:
                        st.markdown(f"""
                        <div class="result-container">
                            <h2 class="result-title">
                                {category_icons.get(pred_label, 'ğŸ“„')} {pred_label}
                            </h2>
                            <p class="result-subtitle">
                                PhÃ¢n loáº¡i: {pred_label}
                            </p>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with confidence_scores:
                        st.markdown('<div class="confidence-container">', unsafe_allow_html=True)
                        st.markdown("**Äá»™ tin cáº­y:**")
                        sorted_indices = np.argsort(confidence)[::-1]
                        for idx in sorted_indices[:3]:
                            name = class_names[idx]
                            conf = confidence[idx]
                            icon = category_icons.get(name, 'ğŸ“„')
                            if idx == pred_idx:
                                st.success(f"{icon} {name}: {conf:.1%}")
                            else:
                                st.info(f"{icon} {name}: {conf:.1%}")
                        st.markdown('</div>', unsafe_allow_html=True)
                else:
                    st.warning("âš ï¸ KhÃ´ng nháº­n diá»‡n Ä‘Æ°á»£c ná»™i dung tá»« áº£nh.")

    with tab2:
        st.markdown("**Nháº­p vÄƒn báº£n HÃ¡n-NÃ´m Ä‘á»ƒ phÃ¢n loáº¡i:**")
        text_input = st.text_area(
            "VÄƒn báº£n HÃ¡n-NÃ´m:",
            height=200,
            placeholder="Nháº­p vÄƒn báº£n HÃ¡n-NÃ´m vÃ o Ä‘Ã¢y...\\n(VÃ­ dá»¥: é‹è¡°æ­»æ²™å ´å®£ç«‹è¬æ˜¥åœ‹)",
            help="Nháº­p vÄƒn báº£n cáº§n phÃ¢n loáº¡i. VÄƒn báº£n cÃ³ thá»ƒ báº±ng chá»¯ HÃ¡n, chá»¯ NÃ´m, hoáº·c há»—n há»£p."
        )
        
        if st.button("ğŸ” PhÃ¢n loáº¡i vÄƒn báº£n", type="primary", key="classify_text"):
            if not text_input.strip():
                st.warning("âš ï¸ Vui lÃ²ng nháº­p vÄƒn báº£n Ä‘á»ƒ phÃ¢n loáº¡i!")
            else:
                with st.spinner("ğŸ”„ Äang phÃ¢n loáº¡i..."):
                    pred_label, confidence, pred_idx = classify_text(
                        text_input, tokenizer, bert_model, lstm_model, 
                        templates, class_names, num_classes, device
                    )
                
                st.markdown("---")
                st.markdown("### ğŸ“Š Káº¿t quáº£ phÃ¢n loáº¡i")
                
                result_col1, result_col2 = st.columns([1, 1])
                with result_col1:
                    st.markdown(f"""
                    <div class="result-container">
                        <h2 class="result-title">
                            {category_icons.get(pred_label, 'ğŸ“„')} {pred_label}
                        </h2>
                        <p class="result-subtitle">
                            PhÃ¢n loáº¡i: {pred_label}
                        </p>
                    </div>
                    """, unsafe_allow_html=True)
                
                with result_col2:
                    st.markdown('<div class="confidence-container">', unsafe_allow_html=True)
                    st.markdown("**Äá»™ tin cáº­y:**")
                    sorted_indices = np.argsort(confidence)[::-1]
                    for idx in sorted_indices[:3]:
                        name = class_names[idx]
                        conf = confidence[idx]
                        icon = category_icons.get(name, 'ğŸ“„')
                        if idx == pred_idx:
                            st.success(f"{icon} {name}: {conf:.1%}")
                        else:
                            st.info(f"{icon} {name}: {conf:.1%}")
                    st.markdown('</div>', unsafe_allow_html=True)
    
    # Footer
    st.markdown("---")
    st.markdown(
        """
        <div style="text-align: center; color: gray;">
            <p>ğŸ“œ <strong>Sino-Nom Text Classification</strong> | BERT-LSTM Model</p>
            <p>6 Classes: Medical, History, Literature, Buddhism, Catholics, Others</p>
            <p><em>ğŸš€ Powered by Streamlit Cloud</em></p>
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()